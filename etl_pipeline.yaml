apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: etl-pipeline-
  annotations: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.18, pipelines.kubeflow.org/pipeline_compilation_time: '2023-01-02T18:40:41.894757',
    pipelines.kubeflow.org/pipeline_spec: '{"description": "an etl pipeline that extract
      data from the internet,loads data and transform data.", "name": "ETL pipeline"}'}
  labels: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.18}
spec:
  entrypoint: etl-pipeline
  templates:
  - name: etl-pipeline
    dag:
      tasks:
      - {name: get-data, template: get-data}
      - name: transform-data
        template: transform-data
        dependencies: [get-data]
        arguments:
          artifacts:
          - {name: get-data-output, from: '{{tasks.get-data.outputs.artifacts.get-data-output}}'}
  - name: get-data
    container:
      args: [--output, /tmp/outputs/output/data]
      command:
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - |
        def _make_parent_dirs_and_return_path(file_path: str):
            import os
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            return file_path

        def get_data(output_path):
            import pandas as pd
            import io
            import requests
            url="https://raw.githubusercontent.com/cs109/2014_data/master/countries.csv"
            s=requests.get(url).content
            c=pd.read_csv(io.StringIO(s.decode('utf-8')))
            c.to_csv(output_path)

        import argparse
        _parser = argparse.ArgumentParser(prog='Get data', description='')
        _parser.add_argument("--output", dest="output_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
        _parsed_args = vars(_parser.parse_args())

        _outputs = get_data(**_parsed_args)
      image: amancevice/pandas
    outputs:
      artifacts:
      - {name: get-data-output, path: /tmp/outputs/output/data}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.18
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
          {"args": ["--output", {"outputPath": "output"}], "command": ["sh", "-ec",
          "program_path=$(mktemp)\nprintf \"%s\" \"$0\" > \"$program_path\"\npython3
          -u \"$program_path\" \"$@\"\n", "def _make_parent_dirs_and_return_path(file_path:
          str):\n    import os\n    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n    return
          file_path\n\ndef get_data(output_path):\n    import pandas as pd\n    import
          io\n    import requests\n    url=\"https://raw.githubusercontent.com/cs109/2014_data/master/countries.csv\"\n    s=requests.get(url).content\n    c=pd.read_csv(io.StringIO(s.decode(''utf-8'')))\n    c.to_csv(output_path)\n\nimport
          argparse\n_parser = argparse.ArgumentParser(prog=''Get data'', description='''')\n_parser.add_argument(\"--output\",
          dest=\"output_path\", type=_make_parent_dirs_and_return_path, required=True,
          default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\n_outputs
          = get_data(**_parsed_args)\n"], "image": "amancevice/pandas"}}, "name":
          "Get data", "outputs": [{"name": "output", "type": "String"}]}', pipelines.kubeflow.org/component_ref: '{}'}
  - name: transform-data
    container:
      args: [--input, /tmp/inputs/input/data]
      command:
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - |
        def transform_data(input_path):
            import pandas as pd
            data=pd.read_csv(input_path)
            tfm_data=data.groupby(by=['Region'])['Country'].apply(list).reset_index()
            print(tfm_data)

        import argparse
        _parser = argparse.ArgumentParser(prog='Transform data', description='')
        _parser.add_argument("--input", dest="input_path", type=str, required=True, default=argparse.SUPPRESS)
        _parsed_args = vars(_parser.parse_args())

        _outputs = transform_data(**_parsed_args)
      image: amancevice/pandas
    inputs:
      artifacts:
      - {name: get-data-output, path: /tmp/inputs/input/data}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.18
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
          {"args": ["--input", {"inputPath": "input"}], "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf
          \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n",
          "def transform_data(input_path):\n    import pandas as pd\n    data=pd.read_csv(input_path)\n    tfm_data=data.groupby(by=[''Region''])[''Country''].apply(list).reset_index()\n    print(tfm_data)\n\nimport
          argparse\n_parser = argparse.ArgumentParser(prog=''Transform data'', description='''')\n_parser.add_argument(\"--input\",
          dest=\"input_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parsed_args
          = vars(_parser.parse_args())\n\n_outputs = transform_data(**_parsed_args)\n"],
          "image": "amancevice/pandas"}}, "inputs": [{"name": "input", "type": "String"}],
          "name": "Transform data"}', pipelines.kubeflow.org/component_ref: '{}'}
  arguments:
    parameters: []
  serviceAccountName: pipeline-runner
